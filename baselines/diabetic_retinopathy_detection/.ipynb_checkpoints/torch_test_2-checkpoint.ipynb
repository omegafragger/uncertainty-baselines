{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce8fd34-78ab-4262-a442-6d536828c397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 10:00:32.844475: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-03 10:00:32.975495: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-03 10:00:32.975517: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-03 10:00:33.005943: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-03 10:00:33.855974: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-03 10:00:33.856041: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-03 10:00:33.856050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "WARNING:absl:Skipped importing the SMCalflow dataset due to ImportError. Try installing uncertainty baselines with the `datasets` extras.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jishnu/Projects/uncertainty_baselines/uncertainty_baselines/datasets/datasets.py\", line 60, in <module>\n",
      "    from uncertainty_baselines.datasets.smcalflow import MultiWoZDataset  # pylint: disable=g-import-not-at-top\n",
      "  File \"/home/jishnu/Projects/uncertainty_baselines/uncertainty_baselines/datasets/smcalflow.py\", line 40, in <module>\n",
      "    import seqio\n",
      "ModuleNotFoundError: No module named 'seqio'\n",
      "WARNING:absl:Skipped importing the Speech Commands dataset due to ImportError. Try installing uncertainty baselines with the `datasets` extras.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jishnu/Projects/uncertainty_baselines/uncertainty_baselines/datasets/datasets.py\", line 72, in <module>\n",
      "    from uncertainty_baselines.datasets.speech_commands import SpeechCommandsDataset  # pylint: disable=g-import-not-at-top\n",
      "  File \"/home/jishnu/Projects/uncertainty_baselines/uncertainty_baselines/datasets/speech_commands.py\", line 29, in <module>\n",
      "    import librosa\n",
      "ModuleNotFoundError: No module named 'librosa'\n",
      "WARNING:absl:Skipped importing the SMCalflow dataset due to ImportError. Try installing uncertainty baselines with the `datasets` extras.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jishnu/Projects/uncertainty_baselines/uncertainty_baselines/datasets/__init__.py\", line 71, in <module>\n",
      "    from uncertainty_baselines.datasets.smcalflow import MultiWoZDataset  # pylint: disable=g-import-not-at-top\n",
      "  File \"/home/jishnu/Projects/uncertainty_baselines/uncertainty_baselines/datasets/smcalflow.py\", line 40, in <module>\n",
      "    import seqio\n",
      "ModuleNotFoundError: No module named 'seqio'\n",
      "WARNING:absl:Skipped importing the Speech Commands dataset due to ImportError. Try installing uncertainty baselines with the `datasets` extras.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jishnu/Projects/uncertainty_baselines/uncertainty_baselines/datasets/__init__.py\", line 81, in <module>\n",
      "    from uncertainty_baselines.datasets.speech_commands import SpeechCommandsDataset  # pylint: disable=g-import-not-at-top\n",
      "  File \"/home/jishnu/Projects/uncertainty_baselines/uncertainty_baselines/datasets/speech_commands.py\", line 29, in <module>\n",
      "    import librosa\n",
      "ModuleNotFoundError: No module named 'librosa'\n",
      "WARNING:absl:Skipped BERT models due to ImportError.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jishnu/Projects/uncertainty_baselines/uncertainty_baselines/models/__init__.py\", line 107, in <module>\n",
      "    from uncertainty_baselines.models import bert\n",
      "  File \"/home/jishnu/Projects/uncertainty_baselines/uncertainty_baselines/models/bert.py\", line 30, in <module>\n",
      "    from official.nlp.bert import bert_models\n",
      "ModuleNotFoundError: No module named 'official.nlp.bert'\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pathlib\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "import uncertainty_baselines as ub\n",
    "import utils  # local file import\n",
    "import wandb\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "DEFAULT_NUM_EPOCHS = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854efaad-cc5f-49c6-8ace-16d2c6d10708",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS:\n",
    "    output_dir = '/media/jishnu/Data/ub_retinopathy_outputs'\n",
    "    eyepacs_data_dir = '/media/jishnu/Data/ub_retinopathy/eyepacs'\n",
    "    aptos_data_dir = '/media/jishnu/Data/ub_retinopathy/aptos'\n",
    "    use_validation = True\n",
    "    use_test = True\n",
    "    preproc_builder_config = 'btgraham-300'\n",
    "    dr_decision_threshold = 'moderate'\n",
    "    load_from_checkpoint = False\n",
    "    checkpoint_dir = None\n",
    "    cache_eval_datasets = False\n",
    "    \n",
    "    use_wandb = False\n",
    "    wandb_dir = 'wandb'\n",
    "    project = 'ub-debug'\n",
    "    exp_name = None\n",
    "    exp_group = None\n",
    "    \n",
    "    distribution_shift = 'severity'\n",
    "    load_train_split = True\n",
    "    \n",
    "    base_learning_rate = 0.023072\n",
    "    final_decay_factor = 0.01\n",
    "    one_minus_momentum = 0.0098467\n",
    "    lr_schedule = 'step'\n",
    "    lr_warmup_epochs = 1\n",
    "    lr_decay_ratio = 0.2\n",
    "    lr_decay_epochs = ['30', '60']\n",
    "    \n",
    "    seed = 42\n",
    "    class_reweight_mode = None\n",
    "    l2 = 0.00010674\n",
    "    train_epochs = DEFAULT_NUM_EPOCHS\n",
    "    per_core_batch_size = 32\n",
    "    checkpoint_interval = 25\n",
    "    num_bins = 15\n",
    "    force_use_cpu = False\n",
    "    use_gpu = True\n",
    "    use_bfloat16 = False\n",
    "    num_cores = 1\n",
    "    tpu = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323d230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 10:00:37.426103: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 10:00:37.426194: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-03 10:00:37.426257: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-03 10:00:37.426319: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-03 10:00:37.426383: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-03 10:00:37.426445: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-03 10:00:37.426508: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-03 10:00:37.426571: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-03 10:00:37.426581: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-10-03 10:00:37.427053: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(FLAGS.seed)\n",
    "wandb_run = None\n",
    "output_dir = FLAGS.output_dir\n",
    "\n",
    "tf.io.gfile.makedirs(output_dir)\n",
    "\n",
    "# Log Run Hypers\n",
    "hypers_dict = {\n",
    "  'per_core_batch_size': FLAGS.per_core_batch_size,\n",
    "  'base_learning_rate': FLAGS.base_learning_rate,\n",
    "  'final_decay_factor': FLAGS.final_decay_factor,\n",
    "  'one_minus_momentum': FLAGS.one_minus_momentum,\n",
    "  'l2': FLAGS.l2\n",
    "}\n",
    "\n",
    "# Initialize distribution strategy on flag-specified accelerator\n",
    "strategy = utils.init_distribution_strategy(FLAGS.force_use_cpu,\n",
    "                                          FLAGS.use_gpu, FLAGS.tpu)\n",
    "use_tpu = not (FLAGS.force_use_cpu or FLAGS.use_gpu)\n",
    "per_core_batch_size = FLAGS.per_core_batch_size * FLAGS.num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8004f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_reweight_mode = FLAGS.class_reweight_mode\n",
    "if class_reweight_mode == 'constant':\n",
    "    class_weights = utils.get_diabetic_retinopathy_class_balance_weights()\n",
    "else:\n",
    "    class_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3ea5b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 10:00:37.531215: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2022-10-03 10:00:37.592374: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "2022-10-03 10:00:37.807041: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"RangeDataset/_3\"\n",
      "op: \"RangeDataset\"\n",
      "input: \"Const/_0\"\n",
      "input: \"Const/_1\"\n",
      "input: \"Const/_2\"\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 9223372036854775807\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\017RangeDataset:13\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-10-03 10:00:37.857878: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2022-10-03 10:00:37.866924: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "2022-10-03 10:00:37.907985: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"RangeDataset/_3\"\n",
      "op: \"RangeDataset\"\n",
      "input: \"Const/_0\"\n",
      "input: \"Const/_1\"\n",
      "input: \"Const/_2\"\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 9223372036854775807\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\017RangeDataset:38\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-10-03 10:00:37.958283: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2022-10-03 10:00:37.967775: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "2022-10-03 10:00:38.012075: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"RangeDataset/_3\"\n",
      "op: \"RangeDataset\"\n",
      "input: \"Const/_0\"\n",
      "input: \"Const/_1\"\n",
      "input: \"Const/_2\"\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 9223372036854775807\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\017RangeDataset:63\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-10-03 10:00:38.064133: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2022-10-03 10:00:38.073595: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "2022-10-03 10:00:38.118135: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"RangeDataset/_3\"\n",
      "op: \"RangeDataset\"\n",
      "input: \"Const/_0\"\n",
      "input: \"Const/_1\"\n",
      "input: \"Const/_2\"\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 9223372036854775807\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\017RangeDataset:88\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-10-03 10:00:38.176959: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2022-10-03 10:00:38.186696: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "2022-10-03 10:00:38.228196: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"RangeDataset/_3\"\n",
      "op: \"RangeDataset\"\n",
      "input: \"Const/_0\"\n",
      "input: \"Const/_1\"\n",
      "input: \"Const/_2\"\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 9223372036854775807\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020RangeDataset:113\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: true\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets, steps = utils.load_dataset(\n",
    "  train_batch_size=per_core_batch_size,\n",
    "  eval_batch_size=per_core_batch_size,\n",
    "  flags=FLAGS,\n",
    "  strategy=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9d02d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 10:11:47.601631: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    }
   ],
   "source": [
    "dataset_iterators = {\n",
    "    'train': iter(datasets['train']),\n",
    "    'in_domain_validation': iter(datasets['in_domain_validation']),\n",
    "    'ood_validation': iter(datasets['ood_validation']),\n",
    "    'in_domain_test': iter(datasets['in_domain_test']),\n",
    "    'ood_test': iter(datasets['ood_test'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "443edc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor([0.0000e+00, 1.6455e-07, 1.7951e-07,  ..., 9.9999e-01, 1.0000e+00,\n",
      "        1.0000e+00], device='cuda:0')\n",
      "tensor([0., 1.], device='cuda:0')\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor([0.0000e+00, 3.5902e-07, 8.3774e-07,  ..., 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00], device='cuda:0')\n",
      "tensor([0., 1.], device='cuda:0')\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor([0.0000e+00, 2.5731e-06, 3.7698e-06,  ..., 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00], device='cuda:0')\n",
      "tensor([1.], device='cuda:0')\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor([0.0000e+00, 5.8342e-07, 1.2566e-06,  ..., 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00], device='cuda:0')\n",
      "tensor([0., 1.], device='cuda:0')\n",
      "torch.Size([32, 3, 512, 512])\n",
      "torch.Size([32])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n",
      "tensor([0.0000e+00, 7.3303e-07, 2.2739e-06,  ..., 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00], device='cuda:0')\n",
      "tensor([1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_torch_inputs(inputs, batch_size, image_h, image_w, device):\n",
    "    images = inputs['features']\n",
    "    labels = inputs['labels']\n",
    "    images = torch.from_numpy(images._numpy()).view(batch_size, 3, image_h, image_w).to(device)\n",
    "    labels = torch.from_numpy(labels._numpy()).to(device).float()\n",
    "    return images, labels\n",
    "\n",
    "# Train\n",
    "image_h = 512\n",
    "image_w = 512\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# iD Train\n",
    "for step in range(steps['train']):\n",
    "    inputs = next(dataset_iterators['train'])\n",
    "    images, labels = get_torch_inputs(inputs, per_core_batch_size, image_h, image_w, device)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    print (images.shape)\n",
    "    print (labels.shape)\n",
    "    print (images.min())\n",
    "    print (images.max())\n",
    "    print (images.unique())\n",
    "    print (labels.unique())\n",
    "    break\n",
    "    \n",
    "# iD val\n",
    "for step in range(steps['in_domain_validation']):\n",
    "    inputs = next(dataset_iterators['in_domain_validation'])\n",
    "    images, labels = get_torch_inputs(inputs, per_core_batch_size, image_h, image_w, device)\n",
    "    print (images.shape)\n",
    "    print (labels.shape)\n",
    "    print (images.min())\n",
    "    print (images.max())\n",
    "    print (images.unique())\n",
    "    print (labels.unique())\n",
    "    break\n",
    "\n",
    "# OoD Val\n",
    "for step in range(steps['ood_validation']):\n",
    "    inputs = next(dataset_iterators['ood_validation'])\n",
    "    images, labels = get_torch_inputs(inputs, per_core_batch_size, image_h, image_w, device)\n",
    "    print (images.shape)\n",
    "    print (labels.shape)\n",
    "    print (images.min())\n",
    "    print (images.max())\n",
    "    print (images.unique())\n",
    "    print (labels.unique())\n",
    "    break\n",
    "    \n",
    "# iD test\n",
    "for step in range(steps['in_domain_test']):\n",
    "    inputs = next(dataset_iterators['in_domain_test'])\n",
    "    images, labels = get_torch_inputs(inputs, per_core_batch_size, image_h, image_w, device)\n",
    "    print (images.shape)\n",
    "    print (labels.shape)\n",
    "    print (images.min())\n",
    "    print (images.max())\n",
    "    print (images.unique())\n",
    "    print (labels.unique())\n",
    "    break\n",
    "\n",
    "# OoD test\n",
    "for step in range(steps['ood_test']):\n",
    "    inputs = next(dataset_iterators['ood_test'])\n",
    "    images, labels = get_torch_inputs(inputs, per_core_batch_size, image_h, image_w, device)\n",
    "    print (images.shape)\n",
    "    print (labels.shape)\n",
    "    print (images.min())\n",
    "    print (images.max())\n",
    "    print (images.unique())\n",
    "    print (labels.unique())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "108fd58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_core_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38378eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# iD Train\n",
    "for step in tqdm(range(steps['train'])):\n",
    "    inputs = next(dataset_iterators['train'])\n",
    "    images, labels = get_torch_inputs(inputs, per_core_batch_size, image_h, image_w, device)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    pass\n",
    "    \n",
    "# iD val\n",
    "for step in tqdm(range(steps['in_domain_validation'])):\n",
    "    inputs = next(dataset_iterators['in_domain_validation'])\n",
    "    images, labels = get_torch_inputs(inputs, per_core_batch_size, image_h, image_w, device)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    pass\n",
    "\n",
    "# OoD Val\n",
    "for step in tqdm(range(steps['ood_validation'])):\n",
    "    inputs = next(dataset_iterators['ood_validation'])\n",
    "    images, labels = get_torch_inputs(inputs, per_core_batch_size, image_h, image_w, device)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    pass\n",
    "    \n",
    "# iD test\n",
    "for step in tqdm(range(steps['in_domain_test'])):\n",
    "    inputs = next(dataset_iterators['in_domain_test'])\n",
    "    images, labels = get_torch_inputs(inputs, per_core_batch_size, image_h, image_w, device)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    pass\n",
    "\n",
    "# OoD test\n",
    "for step in tqdm(range(steps['ood_test'])):\n",
    "    inputs = next(dataset_iterators['ood_test'])\n",
    "    images, labels = get_torch_inputs(inputs, per_core_batch_size, image_h, image_w, device)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4444f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
